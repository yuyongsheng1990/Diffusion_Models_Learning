{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "620c3ff2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:34.273783Z",
     "start_time": "2024-06-12T23:57:34.260103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2024.6.11, implementing diffusion models.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2024.6.11, implementing diffusion models.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a8b71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:50:24.882244Z",
     "start_time": "2024-06-11T04:50:24.878893Z"
    }
   },
   "source": [
    "# DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9593584e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:34.280280Z",
     "start_time": "2024-06-12T23:57:34.276752Z"
    }
   },
   "outputs": [],
   "source": [
    "# Denoising Diffusion Probabilistic Models\n",
    "# https://blog.csdn.net/Peach_____/article/details/128663957"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5110c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:58:37.721320Z",
     "start_time": "2024-06-11T04:58:37.717780Z"
    }
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c713281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:37.921161Z",
     "start_time": "2024-06-12T23:57:34.282271Z"
    }
   },
   "outputs": [],
   "source": [
    "# notebook==6.4.12\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm  # tqdm==4.41.0\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import transforms, datasets  # torchvision==0.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753ae07a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:37.938617Z",
     "start_time": "2024-06-12T23:57:37.922156Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义4种生成β的方法，均需传入总步长T，返回β序列\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps)  # 用于创建一个一维tensor，在start和end之间生成steps均匀分布的values。\n",
    "    alpha_cumprod = torch.cos(((x / timesteps) + s) / (1+s) * torch.pi * 0.5) ** 2  # 计算cos值；**2表示平方运算\n",
    "    alpha_cumprod = alpha_cumprod / alpha_cumprod[0]\n",
    "    betas = 1 - (alpha_cumprod[1:] / alpha_cumprod[:-1])\n",
    "    return torch.clip(betas, 0.0001, 0.9999)\n",
    "\n",
    "def linear_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "def quadratic_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start ** 0.5, beta_end ** 0.5, timesteps) ** 2\n",
    "\n",
    "def sigmoid_beta_shedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    betas = torch.linspace(-6, 6, timesteps)\n",
    "    return torch.sigmoid(betas) * (beta_end - beta_start) + beta_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb6d86ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:37.971649Z",
     "start_time": "2024-06-12T23:57:37.947591Z"
    }
   },
   "outputs": [],
   "source": [
    "# 从序列a中取t时刻的值a[t](batch_size个)，维度与x_shape相同，第一维2为batch_size.\n",
    "def extract(a, t, x_shape):\n",
    "    batch_size = t.shape[0]\n",
    "    out = a.gather(-1, t.cpu())\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) -1 ))).to(t.device)\n",
    "\n",
    "# 扩散过程采样，即通过x0和t计算xt\n",
    "def q_sample(x_start, t, noise=None):\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_start)\n",
    "    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_start.shape)\n",
    "    sqrt_one_minus_alphas_cumpord_t = extract(sqrt_one_minus_alphas_cumpord, t, x_start.shape)\n",
    "    return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumpord_t * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256798b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:37.995836Z",
     "start_time": "2024-06-12T23:57:37.979616Z"
    }
   },
   "outputs": [],
   "source": [
    "# 损失函数loss，共3中计算方式，原文用l2\n",
    "def p_losses(denoise_model, x_start, t, noise=None, loss_type='l1'):\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_start)\n",
    "    x_noisy = q_sample(x_start, t, noise)\n",
    "    predicted_noise = denoise_model(x_noisy, t)\n",
    "    \n",
    "    if loss_type == 'l1':\n",
    "        loss = F.l1_loss(noise, predicted_noise)\n",
    "    elif loss_type == 'l2':\n",
    "        loss = F.mse_loss(noise, predicted_noise)\n",
    "    elif loss_type == 'huber':\n",
    "        loss = F.smooth_l1_loss(noise, predicted_noise)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f61107f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T01:33:24.969913Z",
     "start_time": "2024-06-13T01:33:24.962201Z"
    }
   },
   "outputs": [],
   "source": [
    "# 反向生成过程采样，即通过xt和t计算xt-1，此过程需要通过网络\n",
    "@torch.no_grad()\n",
    "def p_sample(model, x, t, t_index):\n",
    "    betas_t = extract(betas, t, x.shape)\n",
    "    sqrt_one_minus_alphas_cumpord_t = extract(sqrt_one_minus_alphas_cumpord, t, x.shape)\n",
    "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)\n",
    "    \n",
    "    model_mean = sqrt_recip_alphas_t * (x - betas_t * model(x,t) / sqrt_one_minus_alphas_cumpord_t)\n",
    "    if t_index == 0:\n",
    "        return model_mean\n",
    "    else:\n",
    "        posterior_variance_t = extract(posterior_variance, t, x.shape)\n",
    "        noise = torch.randn_like(x)\n",
    "        return model_mean + torch.sqrt(posterior_variance_t) * noise\n",
    "    \n",
    "# 反向生成过程T次采样，即通过xt和t计算xi，获得每一个时刻的图像列表[xi]，此过程需要通过网络\n",
    "@torch.no_grad()\n",
    "def p_sample_loop(model,shape):\n",
    "    device = next(model.parameters()).device\n",
    "    b = shape[0]\n",
    "    img = torch.randn(shape, device=device)\n",
    "    imgs = []\n",
    "    for i in tqdm(reversed(range(0, timesteps)), desc='sampling loop time step', total=timesteps):\n",
    "        img = p_sample(model, img, torch.full((b,), i, device=device, dtype=torch.long), i)\n",
    "        imgs.append(img.cpu())\n",
    "    return imgs\n",
    "\n",
    "# 反向生成过程T次采样，允许传入batch_size指定生成图片的个数，用于生成结果的可视化\n",
    "@torch.no_grad()\n",
    "def sample(model, image_size, batch_size=16, channels=1):\n",
    "    return p_sample_loop(model, shape=(batch_size, channels, image_size, image_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c1594d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T07:23:20.062802Z",
     "start_time": "2024-06-12T07:23:20.058811Z"
    }
   },
   "source": [
    "## models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50cd3d14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:38.062765Z",
     "start_time": "2024-06-12T23:57:38.018860Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from inspect import isfunction\n",
    "from functools import partial\n",
    "\n",
    "from einops import rearrange, reduce\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "import torch\n",
    "from torch import nn, einsum  # einsum用于多维数组操作\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86717a5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:38.078863Z",
     "start_time": "2024-06-12T23:57:38.067748Z"
    }
   },
   "outputs": [],
   "source": [
    "def exist(x):\n",
    "    return x is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exist(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "def Upsample(dim, dim_out=None):\n",
    "    return nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "        nn.Conv2d(dim, default(dim_out, dim), 3, 1, 1)\n",
    "    )\n",
    "\n",
    "def Downsample(dim, dim_out=None):\n",
    "    return nn.Sequential(\n",
    "        Rearrange(\"b c (h p1) (w p2) -> b (c p1 p2) h w\", p1=2, p2=2),\n",
    "        nn.Conv2d(dim*4, default(dim_out, dim), 1, 1, 0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9091c432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:38.091847Z",
     "start_time": "2024-06-12T23:57:38.082874Z"
    }
   },
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super(Residual, self).__init__()\n",
    "        self.fn = fn\n",
    "    \n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.fn(x, *args, **kwargs) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b23069c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:38.127992Z",
     "start_time": "2024-06-12T23:57:38.100821Z"
    }
   },
   "outputs": [],
   "source": [
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(SinusoidalPositionEmbeddings, self).__init__()\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=1)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdffd4dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:38.144758Z",
     "start_time": "2024-06-12T23:57:38.132963Z"
    }
   },
   "outputs": [],
   "source": [
    "class WeightStandardizedConv2d(nn.Conv2d):\n",
    "    def forward(self, x):\n",
    "        eps = 1e-5 if x.dtype == torch.float32 else 1e-3\n",
    "        weight = self.weight\n",
    "        mean = reduce(weight, \"o ...-> o 1 1 1 \", \"mean\")\n",
    "        var = reduce(weight, \"o ...-> o 1 1 1 \", partial(torch.var, unbiased=False))\n",
    "        normalized_weight = (weight - mean) * (var+eps).rsqrt()\n",
    "        \n",
    "        return F.conv2d(\n",
    "            x,\n",
    "            normalized_weight,\n",
    "            self.bias,\n",
    "            self.stride,\n",
    "            self.padding,\n",
    "            self.dilation,\n",
    "            self.groups\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7b5ab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T07:35:13.860625Z",
     "start_time": "2024-06-12T07:35:13.857091Z"
    }
   },
   "source": [
    "### Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f04fdf74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:38.171777Z",
     "start_time": "2024-06-12T23:57:38.150747Z"
    }
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups=8):\n",
    "        super(Block, self).__init__()\n",
    "        self.proj = WeightStandardizedConv2d(dim, dim_out, 3, padding=1)\n",
    "        self.norm = nn.GroupNorm(groups, dim_out)\n",
    "        self.act = nn.SiLU()  # Swish激活函数，x*sigmoid(x)\n",
    "    \n",
    "    def forward(self, x, scale_shift=None):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        if exist(scale_shift):\n",
    "            scale, shift = scale_shift\n",
    "            x = x * (scale + 1) + shift\n",
    "        x = self.act(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4f398d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:38.186438Z",
     "start_time": "2024-06-12T23:57:38.175062Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out, *, time_emb_dim=None, groups=8):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.mlp = (nn.Sequential(nn.SiLU(), nn.Linear(time_emb_dim, dim_out * 2)) if exist(time_emb_dim) else None)\n",
    "        self.block1 = Block(dim, dim_out, groups=groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups=groups)\n",
    "        self.res_conv = nn.Conv2d(dim, dim_out, 1, 1, 0) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb=None):\n",
    "        scale_shift = None\n",
    "        if exist(self.mlp) and exist(time_emb):\n",
    "            time_emb = self.mlp(time_emb)\n",
    "            time_emb = rearrange(time_emb, \"b c -> b c 1 1\")\n",
    "            scale_shift = time_emb.chunk(2, dim=1)\n",
    "\n",
    "        h = self.block1(x, scale_shift=scale_shift)\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d8670",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T08:00:39.277271Z",
     "start_time": "2024-06-12T08:00:39.273906Z"
    }
   },
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cbcc1e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:38.228004Z",
     "start_time": "2024-06-12T23:57:38.213097Z"
    }
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super(Attention, self).__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, 1, 0, bias=False)\n",
    "        self.to_out = nn.Conv2d(hidden_dim, 1, 1,0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
    "        q, k, v = map(lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv)\n",
    "        q = q * self.scale\n",
    "        \n",
    "        sim = einsum(\"b h d i, b h d j -> b h i j\", q, k)\n",
    "        sim = sim - sim.amax(dim=-1, keepdim=True).detach()\n",
    "        attn = sim.softmax(dim=-1)\n",
    "        \n",
    "        out = einsum(\"b h i j, b h d j -> b h i d\", attn, v)\n",
    "        out = rearrange(out, \"b h (x y) d -> b (h d) x y\", x=h, y=w)\n",
    "        return self.to_out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af3f5fa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:38.262263Z",
     "start_time": "2024-06-12T23:57:38.233987Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super(LinearAttention, self).__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, 1, 0, bias=False)\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim, dim, 1, 1,0),\n",
    "            nn.GroupNorm(1, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b,c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
    "        q, k, v = map(lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv)\n",
    "        q = q.softmax(dim=-2)\n",
    "        k = k.softmax(dim=-1)\n",
    "\n",
    "        q = q * self.scale\n",
    "        context = torch.einsum(\"b h d n, b h e n -> b h d e\", k, v)\n",
    "\n",
    "        out = torch.einsum(\"b h d e, b h d n -> b h e n\", context, q)\n",
    "        out = rearrange(out, \"b h c (x y) -> b (h c) x y\",h=self.heads, x=h, y=w)\n",
    "        return self.to_out(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988df63e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T08:13:33.252185Z",
     "start_time": "2024-06-12T08:13:33.248526Z"
    }
   },
   "source": [
    "### Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7c789aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:57:38.322570Z",
     "start_time": "2024-06-12T23:57:38.275231Z"
    }
   },
   "outputs": [],
   "source": [
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super(PreNorm, self).__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = nn.GroupNorm(1, dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, dim, init_dim=None, out_dim=None, dim_mults=(1,2,4,8), channels=3, self_condition=False, \n",
    "                resnet_block_groups=4):\n",
    "        super(Unet, self).__init__()\n",
    "        \n",
    "        self.channels = channels\n",
    "        self.self_condition = self_condition\n",
    "        input_channels = channels * (2 if self_condition else 1)\n",
    "        \n",
    "        init_dim = default(init_dim, dim)\n",
    "        self.init_conv = nn.Conv2d(input_channels, init_dim, 1, 1, 0)\n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "        block_klass = partial(ResnetBlock, groups=resnet_block_groups)\n",
    "        \n",
    "        time_dim = dim * 4\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(dim),\n",
    "            nn.Linear(dim, time_dim),\n",
    "            nn.GELU(),  # 高斯激活函数，Gaussian Error Linear Unit, GELU(x)=x*Φ(x)\n",
    "            nn.Linear(time_dim, time_dim)\n",
    "        )\n",
    "        \n",
    "        self.downs = nn.ModuleList([])\n",
    "        self.ups = nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "            self.downs.append(\n",
    "                nn.ModuleList([\n",
    "                    block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n",
    "                    block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n",
    "                    Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
    "                    Downsample(dim_in, dim_out) if not is_last else nn.Conv2d(dim_in, dim_out, 3, 1, 1)\n",
    "                ])\n",
    "            )\n",
    "        \n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
    "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "        \n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out)):\n",
    "            is_last = ind == (len(in_out) - 1)\n",
    "            self.ups.append(\n",
    "                nn.ModuleList([\n",
    "                    block_klass(dim_out + dim_in, dim_out, time_emb_dim=time_dim),\n",
    "                    block_klass(dim_out + dim_in, dim_out, time_emb_dim=time_dim),\n",
    "                    Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
    "                    Upsample(dim_out, dim_in) if not is_last else nn.Conv2d(dim_out, dim_in, 3, 1, 1)\n",
    "                ])\n",
    "            )\n",
    "        self.out_dim = default(out_dim, channels)\n",
    "        self.final_res_block = block_klass(dim*2, dim, time_emb_dim=time_dim)\n",
    "        self.final_conv = nn.Conv2d(dim, self.out_dim, 1, 1, 0)\n",
    "    \n",
    "    def forward(self, x, time, x_self_cond=None):\n",
    "        if self.self_condition:\n",
    "            x_self_cond = default(x_self_cond, lambda: torch.zeros_like(x))\n",
    "            x = torch.cat((x_self_cond, x), dim=1)\n",
    "        \n",
    "        x = self.init_conv(x)\n",
    "        r = x.clone()\n",
    "        t = self.time_mlp(time)\n",
    "        h=[]\n",
    "        \n",
    "        for block1, block2, attn, downsample in self.downs:\n",
    "            x = block1(x, t)\n",
    "            h.append(x)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_block2(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "        \n",
    "        for block1, block2, attn, upsample in self.ups:\n",
    "            x = torch.cat((x, h.pop()), dim=1)\n",
    "            x = block1(x, t)\n",
    "            x = torch.cat((x, h.pop()), dim=1)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            x = upsample(x)\n",
    "        x = torch.cat((x,r), dim=1)\n",
    "        x = self.final_res_block(x, t)\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447064ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T08:24:36.004041Z",
     "start_time": "2024-06-11T08:24:36.000540Z"
    }
   },
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c754fa55",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-13T01:33:30.257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../dataset/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 9912422/9912422 [00:24<00:00, 406240.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ../dataset/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../dataset/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 28881/28881 [00:00<00:00, 142003.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ../dataset/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../dataset/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1648877/1648877 [00:07<00:00, 207328.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ../dataset/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../dataset/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 4542/4542 [00:00<00:00, 1087172.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../dataset/mnist/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbf9bbd53444014ad58fd46e70bf452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss: 0.0588\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a5d63c033346a68b55c87387a2c1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8c0e3f3e9849b794df10f409863aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss: 0.0267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde2160422d54886addf01a6f934f966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014004ffdec1494ca1539d79ea4f4c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss: 0.0236\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d5427f0ba9466985fe5406a057472e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef2d50fcb1d40cb8cb538cd95ed44eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss: 0.0218\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0d52c2a3804404adac093ef6cab2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a4044cc7e94c96a496cd29552adfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss: 0.0211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cf743475fe4aa190072e0df33d22d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d5a8efe8834f8cb328e72b7296a6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss: 0.0202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f1233cc8af4454bf5095c619fc20b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82456a36fffc4138bbfa7a306dee93ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss: 0.0199\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a00e6dd0824959a7fd37fa4fb29a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8499eda9c340939aa617a3f73e9e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss: 0.0196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137a185d13a44934bcb6424eb2a72fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409884ff91804c3aab38f1f99bfa572c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss: 0.0193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14979ed43b44964ad6ef080f11e661d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6a984063d64b87bdc926cfe81e3a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss: 0.0190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dea00f0028744a3b29f5d66645690d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    timesteps = 300  # 总步长T\n",
    "    # 以下参数均为list，需要传入t获得相应t时刻的值 xt=X[t]\n",
    "    betas = linear_beta_schedule(timesteps=timesteps)  # 选择一种方式，生成β(t)\n",
    "    alphas = 1. - betas  # α(t)\n",
    "    alphas_cumprod = torch.cumprod(alphas, axis=0)  # α的连乘序列，对应α_bar(t)\n",
    "    alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1,0), value=1.0)  # 将α_bar的最后一个值删除，在最开始添加1，对应前一个时刻的α_bar(t-1)\n",
    "    sqrt_recip_alphas = torch.sqrt(1. / alphas)  # 1/根号下α(t)\n",
    "    sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)  # 根号下α_bar(t)\n",
    "    sqrt_one_minus_alphas_cumpord = torch.sqrt(1. - alphas_cumprod)\n",
    "    posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "    \n",
    "    total_epochs = 10\n",
    "    image_size = 28\n",
    "    channels = 1\n",
    "    batch_size = 256\n",
    "    lr = 1e-3\n",
    "    \n",
    "    os.makedirs(\"../dataset/mnist\", exist_ok=True)\n",
    "    os.makedirs(\"images\", exist_ok=True)\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda t: (t*2) - 1)  # 此处将输入数据从(0,1)区间转换到(-1,1)\n",
    "    ])\n",
    "    dataset = datasets.MNIST(root=\"../dataset/mnist\", train=True, transform=transform, download=True)\n",
    "    \n",
    "    reverse_transform = transforms.Compose([  # 将tensor转换为PIL图片\n",
    "        transforms.Lambda(lambda t: (t+1)/2),\n",
    "        transforms.Lambda(lambda t: t.permute(1,2,0)),  # torch重新排列tensor维度的函数\n",
    "        transforms.Lambda(lambda t: t*255),\n",
    "        transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
    "        transforms.ToPILImage()\n",
    "    ])\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = Unet(dim=image_size, channels=channels, dim_mults=(1,2,4))\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(total_epochs):\n",
    "        total_loss = 0\n",
    "        pbar = tqdm(total=len(dataloader), desc=f\"Epoch {epoch+1}/{total_epochs}\", postfix={},\n",
    "                   miniters=0.3)  # tqdm 用于在长时间运行的循环和迭代过程中显示进度条\n",
    "        for iter, (img, _) in enumerate(dataloader):\n",
    "            img = img.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            batch_size = img.shape[0]\n",
    "            t = torch.randint(0, timesteps, (batch_size,), device=device).long()\n",
    "            loss = p_losses(model, img, t, loss_type='huber')  # 选择loss计算方式，计算loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            pbar.set_postfix(**{\"Loss\": loss.item()})\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "        print(\"total_loss: %.4f\" % (total_loss / len(dataloader)))\n",
    "        \n",
    "        # 展示一张图片的生成过程(去噪过程)，每3步生成一张图片，共100张图片(在一张图中展示)\n",
    "        val_images = sample(model, image_size, batch_size=1, channels=channels)\n",
    "        fig, axs = plt.subplots(10, 10, figsize=(20,20))\n",
    "        plt.rc(\"text\", color='blue')\n",
    "        for t in range(100):\n",
    "            i = t // 10\n",
    "            j = t % 10\n",
    "            image = val_images[t * 3 + 2].squeeze(0)\n",
    "            image = reverse_transform(image)\n",
    "            axs[i,j].imshow(image, cmap='gray')\n",
    "            axs[i,j].set_axis_off()\n",
    "            axs[i,j].set_title(\"$q(\\mathbf{x}_{\" + str(300-3*t-3) + \"})$\")\n",
    "        plt.savefig(f\"images/{epoch+1}.png\", bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f74d16-069b-40f7-8021-4f9b49b996bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
